{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Deep Learning Project</center>\n",
    "## <center>Spooky Authors Identification</center>\n",
    "### <center>Fast Text</center>\n",
    "#### <center>Score on Kaggle: 0.57 log loss</center>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*   Eduardo Brendao (MLDM)\n",
    "*   Mohammad Poul Doust (MLDM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46CkY60Xze-G"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "EMCmFb22jDYX",
    "outputId": "c8befcce-119c-4d6b-b45a-9bb676af7984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading test.zip to /content\n",
      "  0% 0.00/538k [00:00<?, ?B/s]\n",
      "100% 538k/538k [00:00<00:00, 34.1MB/s]\n",
      "Downloading sample_submission.zip to /content\n",
      "  0% 0.00/29.4k [00:00<?, ?B/s]\n",
      "100% 29.4k/29.4k [00:00<00:00, 30.7MB/s]\n",
      "Downloading train.zip to /content\n",
      "  0% 0.00/1.26M [00:00<?, ?B/s]\n",
      "100% 1.26M/1.26M [00:00<00:00, 85.3MB/s]\n",
      "Archive:  train.zip\n",
      "  inflating: train.csv               \n",
      "\n",
      "Archive:  sample_submission.zip\n",
      "  inflating: sample_submission.csv   \n",
      "\n",
      "Archive:  test.zip\n",
      "  inflating: test.csv                \n",
      "\n",
      "3 archives were successfully processed.\n"
     ]
    }
   ],
   "source": [
    "#We get the text from Kaggle -- feel free to use my API key :)\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"extremelydifficult\" # username from the json file\n",
    "os.environ['KAGGLE_KEY'] = \"238120927f9705524c124fcbdb19b699\" # key from the json file\n",
    "!kaggle competitions download -c spooky-author-identification\n",
    "!unzip \\*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "id": "oTUmgEQiiqA5",
    "outputId": "f36174a8-4add-4bb4-e369-da0abb086a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastText'...\n",
      "remote: Enumerating objects: 122, done.\u001b[K\n",
      "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
      "remote: Total 3653 (delta 53), reused 67 (delta 27), pack-reused 3531\u001b[K\n",
      "Receiving objects: 100% (3653/3653), 8.16 MiB | 11.26 MiB/s, done.\n",
      "Resolving deltas: 100% (2278/2278), done.\n",
      "Processing ./fastText\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.4.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (42.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.17.5)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2857867 sha256=0de8dbc9aa90c66a04275215bc2247503275d4d68e720c0ef1f5f79e60cb9aef\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1lqj8fki/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.1\n"
     ]
    }
   ],
   "source": [
    "# we get facebook's FastText\n",
    "!git clone https://github.com/facebookresearch/fastText.git\n",
    "! pip install fastText/.\n",
    "# ... and import it\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "xm36tP28ip9a",
    "outputId": "6fbde170-03a5-4cde-fb3f-9227095de313"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6f226b536113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkPB5BFts6Cw"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrhdJW1BqWq3"
   },
   "outputs": [],
   "source": [
    "# First idea is to do minimal preprocessing and adding punctuation as words\n",
    "# The idea is that authors use punctuation distinctively.\n",
    "# Maybe get rid of capitalization?\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "\n",
    "\n",
    "CUSTOM_FILTERS = [strip_multiple_whitespaces, strip_tags]\n",
    "emdash= u\"\\u2014\"\n",
    "ellipsis = u\"\\u2026\"\n",
    "punctuation = list(set(',.:;\\'()\"?!-'))\n",
    "punctuation.append(emdash)\n",
    "punctuation.append(ellipsis)\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "  \"\"\"Things that we were able to find\"\"\"\n",
    "  text = text.replace(\"Dr.\", \"Dr\")\n",
    "  text = text.replace(\"Mr.\", \"Mr\")\n",
    "  text = text.replace(\"Mrs.\", \"Mrs\")\n",
    "  text = text.replace(\"Esq.\", \"Esq\")\n",
    "  text = text.replace(\"Messrs.\", \"Messrs\")\n",
    "  acronym = re.compile(r\"(?<!\\w)([A-Za-z])\\.\")\n",
    "  text = acronym.sub(r\"\\1\", text)\n",
    "  wierd_acronym = re.compile(r\"([A-Z])\\s(?=[A-Z])\")\n",
    "  text = wierd_acronym.sub(r\"\\1\", text)\n",
    "  fake_ellipsis = re.compile(r'(\\. ){3,}')\n",
    "  text = fake_ellipsis.sub(\"\\u2026 \", text)\n",
    "  consecutiveperiods = re.compile(r'\\.{2,}')\n",
    "  text = consecutiveperiods.sub('.', text)\n",
    "  return text\n",
    "\n",
    "def words_as_punctuation_preprocess(text):\n",
    "    \n",
    "    text = preprocess(text)\n",
    "    text = text.replace(\"' \", \" ' \")\n",
    "    prods = set(text) & set(punctuation)\n",
    "    if not prods:\n",
    "        return text\n",
    "    for sign in prods:\n",
    "        text = text.replace(sign, ' {} '.format(sign) )\n",
    "    text = \" \".join(preprocess_string(text, CUSTOM_FILTERS)) #we still have the same problem\n",
    "    # text = \" \".join(fasttext.tokenize(text))\n",
    "    # text = text.encode('utf-8').strip().decode(\"utf-8\", \"strict\") #we had whitespace in EAP\n",
    "    return text.lower()\n",
    "\n",
    " # from the documentation https://github.com/facebookresearch/fastText/tree/master/python#text-classification-model, this is expected behavior: \n",
    " # \"The newline character is used to delimit lines of text. In particular, the EOS token is appended to a line of text if a newline character is encountered.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsJhIetss-Hp"
   },
   "source": [
    "# Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "7B0PzSvFrE5u",
    "outputId": "858cdf8b-f0e2-452c-c9c1-222ea8bebc86"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5e24ff612508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = train.copy()\n",
    "col = ['author', 'text']\n",
    "\n",
    "data = data[col]\n",
    "data['text'] = [words_as_punctuation_preprocess(i) for i in data['text']]\n",
    "data['author']=['__label__'+ s for s in data['author']]\n",
    "data['text']= data['text'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "\n",
    "\n",
    "# We shuffle and save in Facebook's required format\n",
    "data = shuffle(data)\n",
    "data.to_csv(r'/content/data_updated.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "9TQgkeLfrKp0",
    "outputId": "0af3e8ac-4dfc-4faa-df30-3e46da106f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'data_updated.txt' for reading: No such file or directory\n",
      "tail: cannot open 'data_updated.txt' for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# We split the train and test \n",
    "!head -n 18579 data_updated.txt > data.train\n",
    "!tail -n 1000 data_updated.txt > data.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_0DHI__rWTH"
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"data.train\" , autotuneValidationFile='data.valid', lr=0.1, epoch=50, wordNgrams =5, loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFE3zxUoxQCe"
   },
   "outputs": [],
   "source": [
    "data = test.copy()\n",
    "col = ['text']\n",
    "\n",
    "data = data[col]\n",
    "data['text'] = [words_as_punctuation_preprocess(i) for i in data['text']]\n",
    "data['text']= data['text'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "\n",
    "\n",
    "# We shuffle and save in Facebook's required format\n",
    "#data = shuffle(data)\n",
    "data.to_csv(r'/content/data_updated.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vX2fHunkrbb4"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame([])\n",
    "predictions_df = pd.DataFrame(data=[], index=None, columns = ['id','EAP', 'HPL', 'MWS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_uAOda6seQX"
   },
   "outputs": [],
   "source": [
    "prediction_EAP = []\n",
    "prediction_MWS = []\n",
    "prediction_HPL = []\n",
    "\n",
    "for j in data[\"text\"]:\n",
    "  prediction = model.predict(j, k=-1)\n",
    "  for i in zip(prediction[0], prediction[1]):\n",
    "    if i[0] == '__label__EAP':\n",
    "      prediction_EAP.append(i[1])\n",
    "    if i[0] == '__label__MWS':\n",
    "      prediction_MWS.append(i[1])\n",
    "    if i[0] == '__label__HPL':\n",
    "      prediction_HPL.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "AGjgaPw9vQHx",
    "outputId": "b5d1dd12-4778-4a70-8d80-695d8e78c46e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.997988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.986908</td>\n",
       "      <td>0.013082</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.988758</td>\n",
       "      <td>0.011232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.990629</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>0.001556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.339233</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.658964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>id11749</td>\n",
       "      <td>0.997723</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>id10526</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>id13477</td>\n",
       "      <td>0.967930</td>\n",
       "      <td>0.031034</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8390</th>\n",
       "      <td>id13761</td>\n",
       "      <td>0.377701</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.620936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8391</th>\n",
       "      <td>id04282</td>\n",
       "      <td>0.573404</td>\n",
       "      <td>0.426589</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8392 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       EAP       HPL       MWS\n",
       "0     id02310  0.002002  0.000010  0.997988\n",
       "1     id24541  0.986908  0.013082  0.000010\n",
       "2     id00134  0.000010  0.988758  0.011232\n",
       "3     id27757  0.990629  0.007815  0.001556\n",
       "4     id04081  0.339233  0.001804  0.658964\n",
       "...       ...       ...       ...       ...\n",
       "8387  id11749  0.997723  0.000010  0.002267\n",
       "8388  id10526  0.000010  0.000010  0.999980\n",
       "8389  id13477  0.967930  0.031034  0.001036\n",
       "8390  id13761  0.377701  0.001363  0.620936\n",
       "8391  id04282  0.573404  0.426589  0.000006\n",
       "\n",
       "[8392 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['EAP'] = [i if i<=1.0 else 1.0 for i in prediction_EAP]\n",
    "predictions_df['HPL'] = [i if i<=1.0 else 1.0 for i in prediction_HPL]\n",
    "predictions_df['MWS'] = [i if i<=1.0 else 1.0 for i in prediction_MWS]\n",
    "predictions_df['id'] = test['id'].copy()\n",
    "\n",
    "predictions_df[['EAP','HPL','MWS']] = predictions_df[['EAP','HPL','MWS']].div(predictions_df[['EAP','HPL','MWS']].sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgY7Tay53FVv"
   },
   "source": [
    "# Submission\n",
    "0.57771 private score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_cnI_9cvb8y"
   },
   "outputs": [],
   "source": [
    "predictions_df.to_csv(\"fasttext_5gram_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9F3usbJE3Jly"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Spooky Authors Fast Text.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
